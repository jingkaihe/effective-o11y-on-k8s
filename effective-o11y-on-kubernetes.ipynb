{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Effective Observability on Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is observability?\n",
    "\n",
    "Observability (sometimes referred to as o11y) is the concept of gaining an understanding into the behavior and performance of applications and systems. Observability starts by collecting system telemetry data, such as logs, metrics, and traces. More important is how that telemetry is analyzed to diagnose issues, understand the interconnectivity of dependencies, and ensure reliability. - [Honeycomb](https://www.honeycomb.io/blog/what-is-observability-key-components-best-practices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## My Take on Observability\n",
    "\n",
    "Observability simply means how much you know about your IT system behaves and performs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Observability Matters?\n",
    "\n",
    "* You cannot operate a system that you cannot observe or measure.\n",
    "* Empirically speaking there is a strong correlation between level of observability and MTTR (Mean Time To Repair).\n",
    "* Good level of observability brings credibility.\n",
    "* Good level of observability enables continuous delivery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why observability is hard on Kubernetes?\n",
    "\n",
    "* Kubernetes is a complex system with many sub-components and moving parts.\n",
    "* The \"cloud-native\" ecosystem introduces even more surface areas that need to be observable.\n",
    "* There are many observability solutions in the market, which makes it hard to make choices and know where to start, and very easy to veer off the beaten track.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we will cover\n",
    "\n",
    "* How to setup an opinionated production grade observability stack on Kubernetes using Grafana Alloy.\n",
    "* How to effectively instrument your application using Traces, Metrics and Logs with the help of Grafana Alloy.\n",
    "* Deeper insights into your stack using profiling and flamegraphs.\n",
    "\n",
    "### Under the assumptions of...\n",
    "\n",
    "* You use Prometheus-esque TSDB solution.\n",
    "* Your trace backend is OTel compatible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we will not cover\n",
    "\n",
    "* Production grade Mimir/Tempo deployment, they deserve a talk on their own.\n",
    "* Tenant onboarding and lifecycle management on a multi-tenant observability platform. This talk very much focuses on the essence of observability itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Also...\n",
    "\n",
    "I am Jingkai He ðŸ‘‹\n",
    "\n",
    "* I'm an independent software consultant based in London.\n",
    "* I have setup 3 Grafana LGTM-based observability platforms for customers ranging from startups to large enterprises in the past 2 years.\n",
    "* I enjoy crafting software and investigating production crime scenes.\n",
    "* Currently on sabbatical.\n",
    "* I've spent 860 hrs+ of my life on Total War Warhammer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Grafana Alloy?\n",
    "\n",
    "> Alloy offers native pipelines for OTel, Prometheus, Pyroscope, Loki, and many other metrics, logs, traces, and profile tools. \n",
    "\n",
    "> ... Alloy is fully compatible with the OTel Collector, Prometheus Agent, and Promtail. You can use Alloy as an alternative to either of these solutions or combine it into a hybrid system of multiple collectors and agents.\n",
    "\n",
    "From [Grafana Alloy](https://grafana.com/docs/alloy/latest/) official documentation.\n",
    "\n",
    "**Disclaimer**: Despite the vendor neutrality claimed by Grafana, I have not verified it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### High Level Architecture\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph Applications[\"Kubernetes Applications\"]\n",
    "        App1[\"Application\"]\n",
    "    end\n",
    "\n",
    "        \n",
    "    subgraph ObservabilityNamespace[\"Observability Namespace\"]\n",
    "        direction TB\n",
    "        subgraph SupplimentaryServices[\"Supplimentary Services\"]\n",
    "            direction TB\n",
    "            KSM[\"Kube State Metrics\\nDeployment\"]\n",
    "            NodeExporter[\"Node Exporter\\nDaemonSet\"]\n",
    "        end\n",
    "        subgraph AlloySTS[\"Alloy StatefulSet\"]\n",
    "          AlloyProm[\"Prom Collector (metrics)\"]\n",
    "          AlloyOtel[\"Otel Collector (traces)\"]\n",
    "        end\n",
    "        AlloyLog[\"Alloy Logs Collector\\nDaemonSet\\n(Direct read from /var/logs/pods...)\"]\n",
    "        AlloyProfiler[\"Alloy Profiler\\nDaemonSet\\n(Support ebpf-based profiling)\"]\n",
    "    end\n",
    "\n",
    "    subgraph Storage[\"LGTM Stack\"]\n",
    "        direction LR\n",
    "        Mimir[\"Mimir (Metrics)\"]\n",
    "        Tempo[\"Tempo (Traces)\"]\n",
    "        Loki[\"Loki (Logs)\"]\n",
    "        Pyroscope[\"Pyroscope (Continuous profiling)\"]\n",
    "        Grafana[\"Grafana\\nDashboards\"]\n",
    "        AlertManager[\"Alertmanager\"]\n",
    "    end\n",
    "\n",
    "    %% Application connections to collectors\n",
    "    App1 -- HTTP(s) scrape --> AlloyProm\n",
    "    App1 -- otelp --> AlloyOtel\n",
    "    App1 -- HTTP push-based or pprof-scraping-based profiling --> AlloyProfiler\n",
    "\n",
    "\n",
    "    %% Remote connections\n",
    "    AlloyProm -- Remote Write --> Mimir\n",
    "    AlloyLog --> Loki\n",
    "    AlloyOtel -- GRPC --> Tempo\n",
    "    AlloyProfiler -- Remote Write --> Pyroscope\n",
    "\n",
    "    %% Visualization connections\n",
    "    Mimir --> Grafana\n",
    "    Tempo --> Grafana\n",
    "    Loki --> Grafana\n",
    "    Mimir --> AlertManager\n",
    "    AlertManager --> Grafana\n",
    "\n",
    "    %% Styling\n",
    "    classDef k8s fill:#326CE5,color:white\n",
    "    classDef metrics fill:#E6522C,color:white\n",
    "    classDef logs fill:#66B16E,color:white\n",
    "    classDef traces fill:#7D4CDB,color:white\n",
    "    classDef profiles fill:#FFA500,color:white\n",
    "    classDef viz fill:#F8413C,color:white\n",
    "\n",
    "    class App1,App2,App3,KSM,NodeExporter k8s\n",
    "    class Mimir,AlloyProm metrics\n",
    "    class Loki,AlloyLog logs\n",
    "    class Tempo,AlloyOtel traces\n",
    "    class Pyroscope,AlloyProfiler profiles\n",
    "    class Grafana,AlertManager viz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alloy Pros and Cons\n",
    "\n",
    "Pros:\n",
    "* Opinionated (vs [opentelemetry-operator](https://github.com/open-telemetry/opentelemetry-operator)) and easy to setup and get started.\n",
    "* IMO much understandable OTEL pipeline configuration.\n",
    "* Top tier integration with LGTM stack.\n",
    "* Support eBPF based profiling.\n",
    "\n",
    "Cons:\n",
    "* Documentation has always been playing catch up with the product, but it's getting better.\n",
    "* It comes with a HCL-esque DSL called `river` that you will need to learn, but it's not too complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Pretty much like this: https://til.jingkaihe.com/docs/observability-from-hero-to-zero-part-i/#step-2-deploy-the-grafana-alloy-stack-into-your-k8s-cluster\n",
    "\n",
    "Some advices:\n",
    "\n",
    "* https://github.com/grafana/k8s-monitoring-helm/tree/main/charts/k8s-monitoring-v1 is an epic hidden gem. Use it rather than handcrafting your o11y pipeline.\n",
    "* If you are unfamiliar with the LGTM stack or the vendor specific o11y stack, try to rollout logs, metrics, traces and profiles in phases.\n",
    "* Be very hardline with governance labels and attributes enforcement but loose on cardinality guardrails, so that you enable tenants to self-serve and learn at their own pace.\n",
    "* Stop overthinking and just do it :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Customisation for Traces\n",
    "\n",
    "Governance trace attributes:\n",
    "\n",
    "```terraform\n",
    "\n",
    "variable \"traces_external_attributes\" {\n",
    "  description = \"external attributes for traces\"\n",
    "  type        = map(string)\n",
    "\n",
    "  default = {\n",
    "    product_group = \"xxx\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// In your helm config:\n",
    "      traces = {\n",
    "        enabled = true\n",
    "        # traces.receiver.transforms\n",
    "        receiver = {\n",
    "          transforms = {\n",
    "            span = [\n",
    "              for key, value in var.traces_external_attributes : \"set(attributes[\\\"${key}\\\"], \\\"${value}\\\")\"\n",
    "            ]\n",
    "          },\n",
    "          // you can also use `filters` to drop that doesn't have mandatory attributes\n",
    "        }\n",
    "      },\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Customisation for Metrics\n",
    "\n",
    "Removing high cardinality labels (practically it can be highly problematic due to dimension collapsing and causes a lot of duplicated metrics errors):\n",
    "\n",
    "```terraform\n",
    "\n",
    "variable \"metrics_label_drops\" {\n",
    "  description = \"labels to drop from metrics\"\n",
    "  type        = list(string)\n",
    "\n",
    "  default = [\n",
    "    \"id\",\n",
    "    \"uuid\",\n",
    "    \"date\",\n",
    "    \"uid\",\n",
    "    \"container_id\",\n",
    "    \"application_id\",\n",
    "    \"created_at\",\n",
    "    \"client_id\",\n",
    "    \"pod_ip\",\n",
    "    \"image_id\",\n",
    "    \"resource_id\",\n",
    "    \"account_id\",\n",
    "  ]\n",
    "}\n",
    "\n",
    "// In your helm config:\n",
    "      metrics = {\n",
    "        cost = {\n",
    "          enabled = false\n",
    "        },\n",
    "        extraMetricRelabelingRules = <<EOT\n",
    "        rule {\n",
    "          action = \"labeldrop\"\n",
    "          regex = \"${join(\"|\", var.metrics_label_drops)}\"\n",
    "        }\n",
    "        EOT\n",
    "      },\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Customisation for Profiling\n",
    "\n",
    "\n",
    "```terraform\n",
    "      profiles = {\n",
    "        enabled = true\n",
    "        java = {\n",
    "          enabled = false\n",
    "        }\n",
    "        pprof = {\n",
    "          // We are not interested in profiling istio!\n",
    "          extraRelabelingRules = <<-EOT\n",
    "rule {\n",
    "  action = \"drop\"\n",
    "  source_labels = [\"__meta_kubernetes_pod_container_name\"]\n",
    "  regex = \"(istio-init|istio-proxy)\" \n",
    "}\n",
    "rule {\n",
    "  action = \"labeldrop\"\n",
    "  regex = \"${join(\"|\", var.profiles_label_drops)}\"\n",
    "}\n",
    "          EOT\n",
    "        }\n",
    "        ebpf = {\n",
    "          enabled    = true\n",
    "          namespaces = [\"namespace-a\", \"namespace-b\"] // Useful for pilot usage of eBPF-based profiling\n",
    "        }\n",
    "      },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effective application logging\n",
    "\n",
    "### Why logs are useful?\n",
    "\n",
    "Tell you how things are going on the transactional level. \n",
    "IMO it's the cheapest and easiest way to get observability.\n",
    "\n",
    "### Some of the good practices\n",
    "\n",
    "* Just logging to stdout/stderr and have the log-agent daemonset takes care of the log collection.\n",
    "* Do structured logging:\n",
    "  * Human readable.\n",
    "  * Log engine friendly (ideally use logfmt or JSON format).\n",
    "  * Treat logs as slice and dice-able events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Structured logging\n",
    "\n",
    "```go\n",
    "// good because:\n",
    "// 1. Relatively human readable: `message=\"User signed up\" user_id=123 username=\"jingkai\"`\n",
    "// 2. Highly searchable and slice and dice-able as easy as `{service=\"some-service\", user_id=\"123\"} | logfmt`\n",
    "logger.G(ctx).WithField(\"user_id\", 123).WithField(\"username\", \"jingkai\").Info(\"User signed up\")\n",
    "\n",
    "// bad because:\n",
    "// 1. Read like human language but extremely machine unfriendly when it comes to indexing and searching.\n",
    "// 2. You end up with pattern matching and regex to search for things.\n",
    "logger.Info(\"Username %s with id %d has signed up\", \"jingkai\", 123)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Caveats\n",
    "\n",
    "* `json` format log can be a killer to your application performance when you have a excessive amount of logs. It is because `json.Marshal` uses CPU cycles.\n",
    "* `stdout/stderr` can also be a silent killer to your application performance, and is extremely hard to troubleshoot due to reasons of off-CPU nature and dirty write-back.\n",
    "* Overall just avoid excessive logging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effective metrics instrumentation\n",
    "\n",
    "### Why metrics are useful?\n",
    "\n",
    "Great for measuring QoS and signalling potential issues.\n",
    "\n",
    "\n",
    "### What we can measure with metrics?\n",
    "\n",
    "* Latency\n",
    "* Error rate\n",
    "* Throughput\n",
    "* Resource utilisation (CPU, memory, disk, network)\n",
    "* Queue length\n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Categorise metrics\n",
    "\n",
    "### RED method\n",
    "\n",
    "What I use mostly these days since it reflects user experience, thus more SLI/SLO oriented.\n",
    "\n",
    "This is what we will be focusing on in this talk.\n",
    "\n",
    "* Rate: Request per second\n",
    "* Error: Error count per second\n",
    "* Duration: Latency\n",
    "\n",
    "\n",
    "### USE method\n",
    "\n",
    "Useful if you are part of a computing team that manages the underlying infrastructure, but IMO it's becoming less useful if you are using commodtised Kubernetes services.\n",
    "\n",
    "Majority of the telemetry data are scrapped by alloy from node-exporter and cadvisor metrics endpoints.\n",
    "\n",
    "* Utilisation: Resource utilisation (CPU, memory, disk, network)\n",
    "* Saturation: How full is your system (e.g. queue length, CPU, memory saturation)\n",
    "* Errors: Number of error events (e.g. page fault, soft kernel panic, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to collect RED metrics: The low-hanging fruit\n",
    "\n",
    "Scrape metrics from your edge ingress controller/API gateway, NOW!\n",
    "\n",
    "The latency, throughput and error rate from the edge directly translates to user experience, which is invaluable from the perspective of measuring SLI/SLO.\n",
    "\n",
    "```terraform\n",
    "  podAnnotations = {\n",
    "    \"k8s.grafana.com/scrape\"           = \"true\"\n",
    "    \"k8s.grafana.com/job\"              = \"integrations/ingress-nginx\"\n",
    "    \"k8s.grafana.com/metrics.path\"     = \"/metrics\"\n",
    "    \"k8s.grafana.com/metrics.portName\" = \"metrics\"\n",
    "    \"k8s.grafana.com/metrics.scheme\"   = \"http\"\n",
    "  }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to collect RED metrics from your application?\n",
    "\n",
    "```go\n",
    "package metrics\n",
    "\n",
    "import (\n",
    "\t\"context\"\n",
    "\t\"net/http\"\n",
    "\n",
    "\t\"github.com/prometheus/client_golang/prometheus\"\n",
    "\t\"github.com/prometheus/client_golang/prometheus/collectors\"\n",
    "\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n",
    ")\n",
    "\n",
    "var (\n",
    "\tRegistry          = prometheus.NewRegistry()\n",
    "\tHttpRequestsTotal = prometheus.NewCounterVec(\n",
    "\t\tprometheus.CounterOpts{\n",
    "\t\t\tName: \"http_requests_total\",\n",
    "\t\t\tHelp: \"Total number of HTTP requests\",\n",
    "\t\t},\n",
    "\t\t[]string{\"code\", \"method\", \"path\"},\n",
    "\t)\n",
    "\tHttpRequestDuration = prometheus.NewHistogramVec(\n",
    "\t\tprometheus.HistogramOpts{\n",
    "\t\t\tName:    \"http_request_duration_seconds\",\n",
    "\t\t\tHelp:    \"Duration of HTTP requests\",\n",
    "\t\t\tBuckets: prometheus.DefBuckets,\n",
    "\t\t},\n",
    "\t\t[]string{\"code\", \"method\", \"path\"},\n",
    "\t)\n",
    ")\n",
    "\n",
    "func Init(ctx context.Context) {\n",
    "\tRegistry.MustRegister(HttpRequestsTotal)\n",
    "\tRegistry.MustRegister(HttpRequestDuration)\n",
    "\thttp.Handle(\"/metrics\", promhttp.HandlerFor(\n",
    "\t\tRegistry,\n",
    "\t\tpromhttp.HandlerOpts{\n",
    "\t\t\tEnableOpenMetrics: true,\n",
    "\t\t},\n",
    "\t))\n",
    "\n",
    "\tlogger.G(ctx).Info(\"Starting metrics server on :8081\")\n",
    "\tgo http.ListenAndServe(\"0.0.0.0:8081\", nil)\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ... and you can instrument your middleware with\n",
    "\n",
    "```go\n",
    "func Observe(path string) gin.HandlerFunc {\n",
    "    return func(c *gin.Context) {\n",
    "        start := time.Now()\n",
    "\n",
    "        defer func() {\n",
    "            status := c.Writer.Status()\n",
    "            metrics.HttpRequestsTotal.WithLabelValues(strconv.Itoa(status), c.Request.Method, path).Inc()\n",
    "            metrics.HttpRequestDuration.WithLabelValues(strconv.Itoa(status), c.Request.Method, path).Observe(time.Since(start).Seconds())\n",
    "        }()\n",
    "\n",
    "        c.Next()\n",
    "    }\n",
    "}\n",
    "\n",
    "// how it can be used by a middleware\n",
    "r.GET(\"/api/user/:id\", metrics.Observe(\"/api/user/:id\"), handler)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some of the useful metrics queries\n",
    "\n",
    "* `sum by (method, path) (rate(http_requests_total{cluster=\"$cluster\", job=\"$job\"}[$__rate_interval]))` - Rate (throughput) of the given service.\n",
    "* `histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{cluster=\"$cluster\", job=\"$job\"}[$__rate_interval])) by (le))` - Latency at 99th percentile.\n",
    "* `sum (rate(http_requests_total{cluster=\"$cluster\", job=\"$job\", code=~\"5..\"}[$__rate_interval])) / sum(rate(http_requests_total{cluster=\"$cluster\", job=\"$job\"}[$__rate_interval]))` - Service error rate.\n",
    "* `(sum(rate(http_request_duration_seconds_bucket{cluster=\"$cluster\", job=\"$job\", le=\"0.3\"}[$__rate_interval])) + sum(rate(http_request_duration_seconds_bucket{cluster=\"$cluster\", job=\"$job\", le=\"0.6\"}[$__rate_interval]))) / 2 / sum(rate(http_request_duration_seconds_count{cluster=\"$cluster\", job=\"$job\"}[$__rate_interval]))` - [Apdex score](https://en.wikipedia.org/wiki/Apdex).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to collect the metrics (the \"legacy\" way)\n",
    "\n",
    "Use `PodMonitor` CRD to collect metrics from your application.\n",
    "\n",
    "```yaml\n",
    "apiVersion: monitoring.coreos.com/v1\n",
    "kind: PodMonitor\n",
    "metadata:\n",
    "  name: my-app\n",
    "  namespace: the-namespace\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: my-app\n",
    "  podMetricsEndpoints:\n",
    "    - port: metrics # this is a NAME instead of a NUMBER!!!\n",
    "```\n",
    "\n",
    "```yaml\n",
    "containers:\n",
    "- name: my-app\n",
    "  ports:\n",
    "  - name: metrics\n",
    "    port: 8081\n",
    "    protocol: TCP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to collect the metrics (the magic way)\n",
    "\n",
    "Using the undocumented `k8s.grafana.com/job` annotation to collect metrics from your application.\n",
    "\n",
    "```yaml\n",
    "annotations:\n",
    "  k8s.grafana.com/job: my-app\n",
    "  k8s.grafana.com/scrape: \"true\"\n",
    "  k8s.grafana.com/metrics.path: /metrics\n",
    "  k8s.grafana.com/metrics.port: metrics\n",
    "  k8s.grafana.com/scrape.scheme: http\n",
    "  k8s.grafana.com/metrics.scrapeInterval: 60s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effective tracing instrumentation\n",
    "\n",
    "### Why tracing is useful?\n",
    "\n",
    "* Provides you with high-cardinality attributes/context comes with a data flow.\n",
    "* You can find the root cause of an issue via slice and dice the high cardinality attributes.\n",
    "* It allows you to correlate issues across services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to trace - The easy way\n",
    "\n",
    "Use an auto-instrumentation library or in the case of Go you can auto-instrument the binary using a sidecar container as shown below.\n",
    "\n",
    "This is useful to get quick wins and stakeholders buy-in without too much up-front investment, but from my experience it does not correlate between services at all...\n",
    "\n",
    "```terraform\n",
    "      containers = [\n",
    "        {\n",
    "          name  = \"go-auto-otel\"\n",
    "          image = \"otel/autoinstrumentation-go:v0.13.0-alpha\"\n",
    "          env = [\n",
    "            {\n",
    "              name  = \"OTEL_EXPORTER_OTLP_ENDPOINT\"\n",
    "              value = \"http://grafana-k8s-monitoring-grafana-agent.observability.svc.cluster.local:4318\"\n",
    "            },\n",
    "            {\n",
    "              name = \"OTEL_SERVICE_NAME\"\n",
    "              value = \"my-app\"\n",
    "            },\n",
    "            {\n",
    "              name = \"OTEL_GO_AUTO_TARGET_EXE\"\n",
    "              value = \"/app/my-app\"\n",
    "            }\n",
    "          ]\n",
    "          securityContext = {\n",
    "            runAsUser  = 0\n",
    "            privileged = true\n",
    "          }\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to trace - The artisan way\n",
    "\n",
    "Use Otel SDK to manually instrument your application - https://til.jingkaihe.com/docs/observability-from-zero-to-hero-part-iv/#setup-otel-sdk\n",
    "\n",
    "To push the traces to the alloy you need to specify\n",
    "\n",
    "```terraform\n",
    "   - name: OTEL_EXPORTER_OTLP_INSECURE\n",
    "      value: \"true\"\n",
    "    - name: OTEL_EXPORTER_OTLP_ENDPOINT\n",
    "      value: http://grafana-k8s-monitoring-grafana-agent.observability.svc.cluster.local:4318\n",
    "    - name: OTEL_EXPORTER_OTLP_PROTOCOL\n",
    "      value: grpc\n",
    "    - name: OTEL_SERVICE_NAME\n",
    "      valueFrom:\n",
    "        fieldRef:\n",
    "          apiVersion: v1\n",
    "          fieldPath: metadata.labels['app']\n",
    "```\n",
    "as environment variables in your container spec.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Caveats\n",
    "\n",
    "* To makes Otel useful you need to use 3rd party libraries that support it:\n",
    "  * [otelhttp](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/instrumentation/net/http/otelhttp) over standard `net/http` library.\n",
    "  * [gorm](https://github.com/go-gorm/opentelemetry) over `mongo-driver`.\n",
    "  * [ginotel](https://github.com/itsubaki/ginotel).\n",
    "  * [otelsql](https://github.com/XSAM/otelsql) over `database/sql`\n",
    "  * ...\n",
    "* Also in Go always remember to populate the span context all the way down in your stack.\n",
    "* You probably want to sample traces on a great scale for the purpose of reduce cost and avoid overwhelming the backend.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Effective Continuous Profiling using Pyroscope\n",
    "\n",
    "### Why continuous profiling is useful?\n",
    "\n",
    "* It is the way to fully understand the performance issue from the point of view of cpu, memory, threads, block, mutex etc at the level of application runtime.\n",
    "* It eliminates the need to eyeballing and guessing where the performance issue comes from.\n",
    "* Continuous profiling eliminates the painful experience of `git clone https://github.com/brendangregg/FlameGraph` into privileged container and run arbitrary profiling scripts.\n",
    "\n",
    "### How the continuous profiling works?\n",
    "\n",
    "* Instrumented application runtimes are sampled at a low frequency, with the samples sent to the backend.\n",
    "* Profiles are analysed (typically() in the form of flamegraphs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Collect profiles using Alloy - The easy way\n",
    "\n",
    "* The easiest way to get started with continuous profiling is to use the eBPF based profiling.\n",
    "* From my experience it collects Golang and Python based applications out of the box.\n",
    "\n",
    "### Caveats\n",
    "\n",
    "* Only CPU profiles are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other ways to collect profiles\n",
    "\n",
    "* Push-based profiling - https://grafana.com/docs/pyroscope/latest/configure-client/language-sdks/go_push/\n",
    "* pprof-scraping-based profiling - https://grafana.com/docs/pyroscope/latest/configure-client/grafana-alloy/go_pull/#expose-pprof-endpoints It's very much a 3 liner to setup.\n",
    "\n",
    "Configuration for pprof-scraping-based profiling on Kubernetes is very labourious that being said it can easily be optimised via kustomise or sidecar injection.\n",
    "\n",
    "```terraform\n",
    "    spec = {\n",
    "      annotations = {\n",
    "        \"profiles.grafana.com/goroutine.scrape\"    = \"true\"\n",
    "        \"profiles.grafana.com/goroutine.port_name\" = \"pprof\"\n",
    "        \"profiles.grafana.com/goroutine.scheme\"    = \"http\"\n",
    "        \"profiles.grafana.com/goroutine.path\"      = \"/debug/pprof/goroutine\"\n",
    "        \"profiles.grafana.com/block.scrape\"        = \"true\"\n",
    "        \"profiles.grafana.com/block.port_name\"     = \"pprof\"\n",
    "        \"profiles.grafana.com/block.scheme\"        = \"http\"\n",
    "        \"profiles.grafana.com/block.path\"          = \"/debug/pprof/block\"\n",
    "        \"profiles.grafana.com/mutex.scrape\"        = \"true\"\n",
    "        \"profiles.grafana.com/mutex.port_name\"     = \"pprof\"\n",
    "        \"profiles.grafana.com/mutex.scheme\"        = \"http\"\n",
    "        \"profiles.grafana.com/mutex.path\"          = \"/debug/pprof/mutex\"\n",
    "        \"profiles.grafana.com/fgprof.scrape\"       = \"false\"\n",
    "        \"profiles.grafana.com/memory.scrape\"       = \"true\"\n",
    "        \"profiles.grafana.com/memory.port_name\"    = \"pprof\"\n",
    "        \"profiles.grafana.com/memory.scheme\"       = \"http\"\n",
    "        \"profiles.grafana.com/memory.path\"         = \"/debug/pprof/heap\"\n",
    "        \"profiles.grafana.com/cpu.scrape\"          = \"true\"\n",
    "        \"profiles.grafana.com/cpu.port_name\"       = \"pprof\"\n",
    "        \"profiles.grafana.com/cpu.scheme\"          = \"http\"\n",
    "        \"profiles.grafana.com/cpu.path\"            = \"/debug/pprof/profile\"\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo Time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
